PAHSE 1----------------------------------------------------------------------------------------------------


âœ… ReconGPT NER Pipeline: Phase 1 Completed
ğŸ”¹ 1. Selected High-Quality Threat Intelligence Sources
we picked 5 top-tier websites to gather rich cybersecurity data:

MITRE ATT&CK â€” TTPs and adversary behaviors
CISA.gov â€” CVEs, alerts, threat campaigns
TheHackerNews â€” Cyber incident reports
AlienVault OTX â€” Community threat intel & IOCs
Cisco Talos Blog â€” Malware breakdowns & technical reports

ğŸ”¹ 2. Built & Fixed Web Scrapers
Implemented scrapers using requests, BeautifulSoup, and newspaper3k

Fixed Talos parsing errors by dynamically handling missing tags and relative URLs
Exported each article/report as a .txt file

ğŸ”¹ 3. Merged Data into One Dataset
Combined all scraped .txt files into a single all_data.txt file

Verified loading and preview inside a Jupyter notebook

ğŸ”¹ 4. Created IOC Regex Tagger
Developed a custom tag_iocs(text) function to extract:

âœ… IP addresses
âœ… Domain names (strict, realistic TLDs)
âœ… File hashes (MD5, SHA1, SHA256)
âœ… File paths (Unix and Windows)
âœ… File names (e.g., .py, .zip, .exe)
âœ… Email addresses (optional)

ğŸ”¹ 5. Verified Working Extraction
Ran IOC extractor on wer dataset

Verified correct matches (e.g., SHA hashes, Snort.org, file paths)
Identified and corrected false positives like mistaking nvidia.py as a domain

PHASE 2----------------------------------------------------

2. Switched from NLTK to spaCy
Faced issues with NLTK's punkt â†’ switched to spaCy for cleaner tokenization

Installed and loaded spaCy model:

python
Copy code
import spacy
nlp = spacy.load("en_core_web_sm")
Tokenized the document:

python
Copy code
doc = nlp(documents[0].lower())
tokens = [token.text for token in doc]
âœ… 3. Generated Bigrams
Used nltk.bigrams() on tokens:

python
Copy code
from nltk import bigrams
bi_tokens = list(bigrams(tokens))
Sample output:

css
Copy code
[('famous', 'chollima'), ('chollima', 'deploying'), ('deploying', 'python'), ...]
âœ… 4. Encoded Bigrams to Integer IDs
Created a vocabulary of unique bigrams:

python
Copy code
bigram_vocab = {bg: idx for idx, bg in enumerate(set(bi_tokens))}
bigram_ids = [bigram_vocab[bg] for bg in bi_tokens]
Result: numerical sequence of document in bigram form

âœ… What You Now Have
Artifact	Description
tokens	Word tokens from threat intel corpus
bi_tokens	List of token bigrams
bigram_vocab	Mapping from bigram â†’ integer ID
bigram_ids	Numerical encoding of your entire document



Phase 3----------------------------------------------------------------------------------------------------------
ğŸ” Phase 3-A: IOC Entity Labeling via Regex
Weâ€™ll define patterns for:

Entity Type	Label	Example
IP Address	B-IP	192.168.1.1
Domain	B-DOMAIN	malicious-example.com
Hash	B-HASH	d41d8cd98f00b204e9800998ecf8427e
Filepath	B-FILE	/usr/bin/malware
Filename	B-FILE	update.dll